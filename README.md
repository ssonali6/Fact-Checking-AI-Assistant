# ğŸ§  Deep Research AI Agent

## ğŸ“Œ Overview
This project implements a **Deep Research AI Agentic System** using **Tavily for web crawling**, with **LangChain & LangGraph** for multi-agent processing. The system consists of:

1. **Research Agent** â€“ Collects relevant articles.  
2. **Fact-Checking Agent** â€“ Analyzes credibility and verifies claims.  

The project is built using **Python, Streamlit, LangChain, LangGraph, and Tavily**.  


## ğŸ“Œ Features
âœ… Uses **Tavily API** for online research  
âœ… Leverages **LangGraph & LangChain** for multi-agent workflow  
âœ… Extracts keywords using **spaCy**  
âœ… Fact-checks claims using **Llama3**  
âœ… Generates structured fact-checking reports  


## ğŸ“Œ Installation & Setup
### **1ï¸âƒ£ Install Dependencies**


ğŸ“Œ Architecture
ğŸ”¹ Multi-Agent System

| ğŸ— **Agent**              | ğŸ” **Function**                                   |
|---------------------------|---------------------------------------------------|
| **Research Agent**        | Collects relevant articles from Tavily & Wikipedia|
| **Fact-Checking Agent**   | Assigns reliability scores & verifies claims      |

ğŸ”¹ Workflow
1ï¸âƒ£ User enters a claim â†’
2ï¸âƒ£ Research Agent collects data â†’
3ï¸âƒ£ Fact-Checking Agent verifies the claim â†’
4ï¸âƒ£ Draft Agent summarizes findings â†’
âœ… Result is displayed in Streamlit with sources & reliability scores.

ğŸ“Œ How to Use
Enter a claim in the Streamlit web app
Press "Enter"
View Fact-Check Results with reliability scores 
Download full report (Markdown)

## ğŸ“Œ Repository Structure  
```
â”œâ”€â”€ app.py # Main Streamlit app
â”œâ”€â”€ config.yaml # Search & API configurations
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ fact_checking_agent.ipynb # Google Colab notebook
```
âœ… 1ï¸âƒ£ Step-by-Step Demo Flow

## **ğŸ“Œ Step 1: Open Google Colab & Launch Ollama**  
Since this project requires **Ollama (Llama 3)** for fact-checking, it must be installed and launched before running Streamlit.  

### **â–¶ 1ï¸âƒ£ Open the Google Colab Notebook**  
[Click here to open the Colab notebook](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/fact_checking_agent.ipynb)

### **â–¶ 2ï¸âƒ£ Install Ollama & Launch It**  
Run these commands inside the Colab notebook:  
```bash
!pip install colab-xterm
%load_ext colabxterm
%xterm
```

Once the terminal opens, run these commands inside the **xterm terminal**:
```bash
curl https://ollama.ai/install.sh | sh
ollama serve & ollama pull llama3  # (Once this is done running, press "Ctrl + Enter")
ollama pull llama3
```
ğŸ”¹ This installs Ollama and pulls the Llama 3 model for fact-checking.

## **ğŸ“Œ Step 2: Install Requirements & Run All Cells**  

Before starting the Streamlit app, follow these steps:  

### **â–¶ 1ï¸âƒ£ Install Required Dependencies**  
Run this in **Google Colab**:  
```python
!pip install langchain-ollama tavily-python langgraph langchain langchain-community
!pip install wikipedia-api transformers streamlit pyyaml pyngrok ngrok
```

### **â–¶ 2ï¸âƒ£ Run All Notebook Cells**  

ğŸ”¹ **Run all the cells** once packages are installed in Google Colab.  
ğŸ”¹ This will **set up all agents, load models, and prepare the system**.  
ğŸ”¹ **Enter your own Tavily API key** when prompted.


### ğŸ“Œ Step 3: Start the Streamlit App in Google Colab  

First, expose the app using ngrok and add the ngrok authorization token:  
```python
from pyngrok import ngrok

ngrok.set_auth_token("your_ngrok_auth_token")

public_url = ngrok.connect(addr=8501, proto="http", auth=None)

print("Streamlit app is running at:", public_url)
```
After running all cells, start Streamlit:

```
!streamlit run /content/app.py &>/dev/null&
```

Finally! Click on the ngrok link generated in output section and open it in your browser.

## ğŸ“Œ Demo Screenshots  

### ğŸ  Streamlit Interface  
![Streamlit Interface](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/streamlit_interface.png)

### ğŸ” Fact-Check Result  
![Fact-Check Result](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/fact_check_result.png)  

### âœ Draft Answer  
![Draft Answer](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/draft_answer.png)

### âš  Bias Detection & Source Reliability Scores Table
![Bias Detection](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/bias_detection.png)  

### ğŸ“Š Source Reliability Chart  
![Source Reliability](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/source_reliability.png) 

### ğŸ“¥ Downloading the Report  
![Download Report Button](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/download_report_button.png)

### ğŸ“„ Viewing the Downloaded Report  
![Downloaded Report](https://github.com/ssonali6/Fact-Checking-AI-Assistant/blob/main/downloaded_report.png)  





